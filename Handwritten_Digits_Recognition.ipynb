{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaYdP1KHp3n/icnoRWv3a/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravinasha/mac/blob/main/Handwritten_Digits_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "150hdfaU95ZS",
        "outputId": "8c91063f-1559-479c-e9d1-952370aec37e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train size: (5043, 784)\n",
            "X_cv size: (1261, 784)\n",
            "X_test size: (5166, 784)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "51/51 - 1s - loss: nan - accuracy: 0.1624 - val_loss: nan - val_accuracy: 0.0880 - 1s/epoch - 21ms/step\n",
            "Epoch 2/20\n",
            "51/51 - 0s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 358ms/epoch - 7ms/step\n",
            "Epoch 3/20\n",
            "51/51 - 0s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 353ms/epoch - 7ms/step\n",
            "Epoch 4/20\n",
            "51/51 - 0s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 347ms/epoch - 7ms/step\n",
            "Epoch 5/20\n",
            "51/51 - 0s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 342ms/epoch - 7ms/step\n",
            "Epoch 6/20\n",
            "51/51 - 0s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 364ms/epoch - 7ms/step\n",
            "Epoch 7/20\n",
            "51/51 - 0s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 377ms/epoch - 7ms/step\n",
            "Epoch 8/20\n",
            "51/51 - 0s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 366ms/epoch - 7ms/step\n",
            "Epoch 9/20\n",
            "51/51 - 0s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 363ms/epoch - 7ms/step\n",
            "Epoch 10/20\n",
            "51/51 - 0s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 379ms/epoch - 7ms/step\n",
            "Epoch 11/20\n",
            "51/51 - 1s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 606ms/epoch - 12ms/step\n",
            "Epoch 12/20\n",
            "51/51 - 1s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 528ms/epoch - 10ms/step\n",
            "Epoch 13/20\n",
            "51/51 - 1s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 556ms/epoch - 11ms/step\n",
            "Epoch 14/20\n",
            "51/51 - 1s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 557ms/epoch - 11ms/step\n",
            "Epoch 15/20\n",
            "51/51 - 1s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 523ms/epoch - 10ms/step\n",
            "Epoch 16/20\n",
            "51/51 - 0s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 347ms/epoch - 7ms/step\n",
            "Epoch 17/20\n",
            "51/51 - 0s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 386ms/epoch - 8ms/step\n",
            "Epoch 18/20\n",
            "51/51 - 0s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 378ms/epoch - 7ms/step\n",
            "Epoch 19/20\n",
            "51/51 - 0s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 366ms/epoch - 7ms/step\n",
            "Epoch 20/20\n",
            "51/51 - 0s - loss: nan - accuracy: 0.1021 - val_loss: nan - val_accuracy: 0.0880 - 352ms/epoch - 7ms/step\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras import optimizers\n",
        "\n",
        "np.random.seed(1212)\n",
        "\n",
        "# Load the data\n",
        "df_train = pd.read_csv('/content/train.csv')\n",
        "df_test = pd.read_csv('/content/test.csv')\n",
        "\n",
        "# Split features and labels\n",
        "df_features = df_train.iloc[:, 1:785]\n",
        "df_label = df_train.iloc[:, 0]\n",
        "\n",
        "# Split train and validation sets\n",
        "X_train, X_cv, y_train, y_cv = train_test_split(df_features, df_label,\n",
        "                                                test_size=0.2,\n",
        "                                                random_state=1212)\n",
        "print(\"X_train size:\", X_train.shape)\n",
        "print(\"X_cv size:\", X_cv.shape)\n",
        "print(\"X_test size:\", X_test.shape)\n",
        "\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_cv = X_cv.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Convert labels to One Hot Encoded\n",
        "num_digits = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_digits)\n",
        "y_cv = keras.utils.to_categorical(y_cv, num_digits)\n",
        "\n",
        "# Model architecture\n",
        "n_input = 784\n",
        "n_hidden_1 = 300\n",
        "n_hidden_2 = 100\n",
        "n_hidden_3 = 100\n",
        "n_hidden_4 = 200\n",
        "\n",
        "Inp = Input(shape=(784,))\n",
        "x = Dense(n_hidden_1, activation='relu', name=\"Hidden_Layer_1\")(Inp)\n",
        "x = Dense(n_hidden_2, activation='relu', name=\"Hidden_Layer_2\")(x)\n",
        "x = Dense(n_hidden_3, activation='relu', name=\"Hidden_Layer_3\")(x)\n",
        "x = Dense(n_hidden_4, activation='relu', name=\"Hidden_Layer_4\")(x)\n",
        "output = Dense(num_digits, activation='softmax', name=\"Output_Layer\")(x)\n",
        "\n",
        "# Model compilation and training\n",
        "learning_rate = 0.1\n",
        "training_epochs = 20\n",
        "batch_size = 100\n",
        "sgd = optimizers.SGD(lr=learning_rate)\n",
        "model = Model(Inp, output)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=training_epochs,\n",
        "                    verbose=2,\n",
        "                    validation_data=(X_cv, y_cv))\n",
        "\n",
        "# Make predictions on the test set\n",
        "test_pred = model.predict(X_test, batch_size=200)\n",
        "test_pred = pd.DataFrame(test_pred.argmax(axis=1), columns=['Label'])\n",
        "test_pred.index.name = 'ImageId'\n",
        "test_pred.index += 1\n",
        "test_pred.to_csv('/content/submission.csv')\n"
      ]
    }
  ]
}